---
title: "MCP 架构下，提示词工程和标准化数据结构越加重要"
description: "MCP 架构下，提示词工程和标准化数据结构越加重要"
date: "2025-04-14"
category: "article"
keywords: ["Higress"]
authors: "CH3CHO"
---

对于工程师而言，LLM 应用的最大区别之一是不确定的数据结构。非 LLM 应用的服务调用逻辑是确定的，由工程师们进行定义；而 LLM 应用的服务调用逻辑和输出，则是由 LLM 进行定义。  
  
因此，当我们用自然语言在客户端描述请求的时候，LLM 对请求识别的准确度，决定了 LLM 输出的准确程度。另外，工作流越复杂，MCP Server 越多，对信息传递的要求越高。  
  
这很像以前大家玩的“肢体传话游戏”，自然语言的使用限制越多、传递的人越多，结果可能相距越远。由于 MCP 引入了更多的处理和传递环节，这就更加要求：传递过程中，标准化数据结构，提升数据的可读性和处理效率，并通过提示词工程，以引导大模型获得预期的响应。  
  
其中，提升数据的可读性和处理效率，是发挥提示词工程作用的前提，[Higress 发布了对 MCP Server 配置进行自动调优的能力](https://mp.weixin.qq.com/s?__biz=MzU0MzkyMTgzNg==&mid=2247486160&idx=1&sn=f9139d5a37f9b8793fa6f1e177111bf3&scene=142#wechat_redirect)，让数据结构更清晰、重点更突出、语义更明确、上下文更完整。  


近期，Google 发布了《Promt Engineering》电子书。我们提取了一些关键词，全文翻译和导读见文末。  


**提示词配置：**

+ 输出长度：设置太短，模型可能无法表达完整；设置太长，不仅费时、费钱，还可能产生没用的内容。
+ Temprature：控制模型回答的随机程度。温度低，模型就比较 “保守”，回答更确定；温度高，回答就更有创意、更随机。
+ top-K 和 top-P 都是统计学上的抽样参数，top-K 是选最可能的前 K 个词，top-P 是选累计概率不超过某个值的词，参数越低，模型就比较 “保守”，回答更确定；参数越高，回答就更有创意、更随机。  


**提示词技巧：**

+ Chain of Thought：逐步思考，让模型在回答问题时，把思考过程一步步写出来，这样能提高回答的准确性，像做数学题，一步步推理就不容易错。
+ Self-Consistency：自一致性，通过多次生成答案，然后选出现次数最多的那个，来提高回答的准确性。
+ Tree of Thoughts：思维树，让模型生成多个不同的思维路径，并进行探索比对，适用于解决复杂的任务。  


**导读和翻译：https://lxblog.com/efficiency/U/5qDhTBkma5z9sE09ZeuLtPkFp4dgHJ5X**


